<article xmlns="http://www.w3.org/1999/html">
    <div>
        <h1><span class="title">Circular Buffer</span></h1>
        <time datetime="2021-07-10">10 July 2021</time>
        <div class="authors">
            <span class="author">Es</span>
        </div>
        <div class="tags">
            <span class="tag">C99</span>
            <span class="tag">Data Structure</span>
            <span class="tag">Linux</span>
        </div>
    </div>
    <div class="post-text">

        <div class="auto-toc"></div>

        <p><span class="summary">A circular buffer is a really cool fixed-sized FIFO data-structure useful when passing a stream of data from a '<i>producer</i>' and '<i>consumer</i>' thread.</span></p>

        <h2>What is it?</h2>

        <figure class="center three-quarter-width">
            <a href="figures/flat-buffer.svg"><img src="figures/flat-buffer.svg" alt="Buffer" /></a>
            <figcaption>Fig.1 Repeating buffer</figcaption>
        </figure>

        <p>A circular buffer (a.k.a. ring buffer) is a fix-sized data-structure that loops back to the beginning when the end is reached. It is continuous, repeating and  usually used to buffer streams.</p>

        <p>Two positions are tracked:</p>
        <ul>
            <li>the write position (<code class="inline" style="color: darkred">w</code>) which moves as data is written to the buffer, and</li>
            <li>the read position (<code class="inline" style="color: royalblue">r</code>) which moves as data is read from the buffer.</li>
        </ul>

        <figure class="right third-width">
            <a href="figures/circular-buffer.svg"><img src="figures/circular-buffer.svg" alt="Circular Buffer" /></a>
            <figcaption>Fig.2 Circular buffer representation</figcaption>
        </figure>

        <p>Both move clockwise on the ring and point to the start position on the buffer of their respective processes.</p>

        <p>Circular buffers are essentially Queues with <b>fixed maximum sizes</b>. Their content is consumed using a FIFO method (first-in, first-out).</p>

        <div class="information-box">
            <p><b class="underline">Things to keep in mind</b></p>
            <ul>
                <li>The read position (<code class="inline" style="color: royalblue">r</code>) will always be conceptually 'behind' or equal to the write position (<code class="inline" style="color: darkred">w</code>) even when not in actuality.</li>
                <li>The read position should never read past the write position.</li>
                <li>When the read and write positions (<code class="inline" style="color: royalblue">r</code>, <code class="inline" style="color: darkred">w</code>) are the same it can mean one of two possible state for the buffer: <i>completely empty</i> or <i>completely full</i>.</li>
            </ul>
        </div>

        <h2>Design considerations</h2>

        <p>The simple way of making a circular buffer is through an array. The primary issues to contend with are:</p>
        <ol>
            <li>the behaviour of the fill/drain operations respective to the availability of space/data on the buffer,</li>
            <li>how to keep track of whether the array is full or empty when the <code class="inline" style="color: royalblue">r</code> and <code class="inline" style="color: darkred">w</code> positions are the same,</li>
            <li>circling back to the beginning when reaching the end of the array, and</li>
            <li>avoiding race conditions with threads.</li>
        </ol>

        <h3>Fill/Drain behaviour</h3>

        <p>The behaviour of these operations comes down to what the circular buffer will be used for and how. When the requested size of data for an operation is not currently available, data for reading and free space for writing, there are 3 possible approach:</p>
        <ol>
            <li>All-or-nothing (i.e. fail and return straight away when resources are not enough),</li>
            <li>Process what can be processed given the available resources (see fig.3),</li>
            <li>Wait until the resource needed are available.</li>
        </ol>

        <figure class="right half-width">
            <a href="figures/try-my-best.svg"><img src="figures/try-my-best.svg" alt="Try my best operation" /></a>
            <figcaption>Fig.3 Try-my-best operations</figcaption>
        </figure>

        <p>All-or-nothing means that the operation won't block the calling thread but will need to be tried again later on failure.</p>

        <p>Processing what can be processed at the time means not blocking the calling thread waiting until enough resources are available. Though, like 'Fail', there will need to be another call to the operation later to process the remaining data.</p>

        <p>Waiting means the call will block the calling thread until the resources required are available and processed. At least, with this, there won't be another call from the calling thread to try again or resume processing whatever was not.</p>

        <p>All of these come with their own pros and cons and each are suited for particular scenarios.</p>

        <h3>Dealing with Full/Empty states</h3>

        <p>To keep track of the empty/full state, a simple flag be set to signal whether the buffer has some data or is completely empty. </p>

        <figure class="right half-width">
            <a href="figures/edge-state-seq.svg"><img src="figures/edge-state-seq.svg" alt="Sequential empty to full" /></a>
            <figcaption>Fig.4 Sequential fill/drain buffer data</figcaption>
        </figure>

        <p>For example (see fig.3):</p>
        <ul>
            <li>A buffer of size <i>s</i> is initialised and its <code class="inline">empty</code> flag is set to <code class="inline">true</code>.</li>
            <li>The <i>producer</i> process writes <i>n</i> bytes of data (<code class="inline"><span style="color: darkred">w</span> += <i>n</i></code>). This sets the <i>empty</i> flag to <code class="inline">false</code>.</li>
            <li>Next, <i>n</i> bytes of data is read by the <i>consumer</i> process (<code class="inline"><span style="color: royalblue">r</span> += <i>n</i></code>). This last event makes <code class="inline" style="color: darkred">w</code> equal to <code class="inline" style="color: royalblue">r</code> and so, since there's no more data left to read, the <code class="inline">empty</code> flag is set back to <code class="inline">true</code>.</li>
        </ul>

        <div class="warning-box">
            <p>When implementing a flag system to keep track of the empty/full states, it's important to be careful especially if the read/write operations are <b>non-blocking</b> as it can lead to <b>race-conditions</b>.</p>
        </div>

        <h3>Circling back</h3>

        <p>When advancing the write or read positions, some care must be taken in the event adding <i>n</i> makes the position equal or larger than the underlining array's size. This happens when the positions circle back to the beginning. To avoid this, the modulo operator can be used to make sure the index calculated is always correct...</p>

        <div class="information-box">
            <p><b class="underline">Calculations</b></p>
            <p><code class="inline">position = ( position + <i>n</i> ) % array_size </code></p>
            <p><code class="inline">free_space = ( <span style="color:royalblue;">r</span> + array_size - <span style="color: darkred;">w</span> ) % array_size </code></p>
        </div>

        <h4>Copy byte-per-byte</h4>

        <p>A 'naive' implementation of the circular buffer's fill or drain operations would use a 'byte-by-byte' approach.</p>

        <div class="code-wrap">
            <code class="clang block">bool fill( CircularBuffer_t * cbuff, uint8 * src, size_t n ) {
    const size_t free_space = ( ( cbuff->read_pos + cbuff->size - cbuff->write_pos ) % cbuff->size );

    if( free_space &lt; n )
        return false;

    for( size_t i = 0; i &lt; n; ++i ) {
        cbuff->buffer[ ( cbuff->write_pos + i ) % cbuff->size ] = src[ i ];
    }

    if( n ) {
        cbuff->write_pos = ( cbuff->write_pos + size ) % cbuff->size;
        cbuff->empty     = false;
    }

    return true;
}</code>
        </div>
        <div class="caption-bottom">Byte-per-byte buffer fill (NOT thread-safe)</div>

        <p>This is not exactly efficient by any means as a modulo operation is made for every single byte bringing the performance down. A better way would be to do 'copy-by-chunk' instead.</p>

        <h4>Copy by chunks</h4>

        <p>Copying entire sections requires using <code class="terminal inline">memcpy(..)</code> or an equivalent if using another language than C.</p>

        <p>For buffer operations, when the starting position is <code class="inline">&lt</code> the end position, no circling back is needed as the free space is a whole contiguous block (see fig.4a). For writing it would be <code class="inline"><span style="color: darkred">w</span> &lt; <span style="color: royalblue">r</span></code> and, for reading the same applies when <code class="inline"><span style="color: royalblue">r</span> &lt; <span style="color: darkred">w</span></code>.</p>

        <figure class="center fill">
            <a href="figures/chunking.svg"><img src="figures/chunking.svg" alt="Chunking states" /></a>
            <figcaption>Fig.5 Chunking states</figcaption>
        </figure>

        <p>When the free space is not a one-piece physical block some allowances need to be made. There are 2 cases that require "chunking" calculations:</p>
        <ol>
            <li>Where the starting position is <code class="inline">&gt;</code> to the end position (see fig.4b), and</li>
            <li>Where the starting position is <code class="inline">==</code> to the end position (see fig.4c).</li>
        </ol>

        <p>Both may very well lead to no actual chunking if the amount to copy is lesser or equal to the size of the first chunk of free space before the circling back occurs.</p>

        <p>In any case, processing can be done with just 2 modulo operation instead of the <math>O(n+2)</math> found in the 'byte-per-byte' approach. One modulo to find the amount of free space in the buffer and the other for moving the position up. Both are already a fixture in the previous approach anyway.</p>

        <div class="code-wrap">
            <code class="clang block">bool fill( CircularBuffer_t * cbuff, uint8 * src, size_t n ) {
    const size_t free_space = ( ( cbuff->read_pos + cbuff->size - cbuff->write_pos ) % cbuff->size );

    if( free_space &lt; n )
        return false;

    if( cbuff->read_pos &gt; cbuff->write_pos ) { //no circling back
        memcpy( &cbuff->buffer[cbuff->write_pos], src, n );

    } else { //circling back (i.e. 1-2 x chunks)
        const size_t free_chunk1 = cbuff->size - cbuff->write_pos;
        const size_t chunk1_size = ( n &lt;= free_chunk1 ? n : free_chunk1 );

        memcpy( &cbuff->buffer[cbuff->write_pos], src, chunk1_size );

        if( n &gt; free_chunk1 )
            memcpy( &cbuff->buffer[0], &src[chunk1_size], ( n - free_chunk1 ) );
    }

    if( n ) {
        cbuff->write_pos = ( cbuff->write_pos + size ) % cbuff->size;
        cbuff->empty     = false;
    }

    return true;
}</code>
        </div>
        <div class="caption-bottom">By-chunk buffer fill (NOT thread-safe)</div>

        <p>This is already pretty nice but there is another pretty neat approach to the fill/drain operations...</p>

        <h3>Using the memory mapping trick</h3>

        <p>Instead of dealing with the physical array directly a 'virtual' mapping can be created as a proxy instead. A second virtual map of the array can then be appended to the end of the first and, thus, allowing for copy operations to happen in 1-chunk even if there's a circle-back.</p>

        <figure class="center fill">
            <a href="figures/mmap.svg"><img src="figures/mmap.svg" alt="Virtual memory map" /></a>
            <figcaption>Fig.6 Virtual memory map</figcaption>
        </figure>

        <p>Depending on what platform and what virtual memory mapping library is being used some details may be different. That being said, the way this works in Linux is by:</p>
        <ul>
            <li>creating a memory file descriptor to the physical array and adjusting its size to the array's,
                <code class="clang block">int fd = syscall( __NR_memfd_create, "circular_buffer", 0 );
ftruncate( fd, size )</code>
            </li>
            <li>initialising a blank anonymous memory map with 2 times the size of the array,
                <code class="clang block">u_int8_t * buffer = mmap( NULL, 2 * size, PROT_NONE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0 );</code>
            </li>
            <li>assigning the file descriptor on the map at the beginning and, again, at the size offset.
                <code class="clang block">mmap( cbuff->buffer, size, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_FIXED, fd, 0 );
mmap( ( cbuff->buffer + size ), size, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_FIXED, fd, 0 );</code>
            </li>
        </ul>

        <p>Now the resulting map allows for the array to be doubly accessible (see fig.5).</p>

        <div class="information-box">
            <p>In Linux, for the memory mapping trick requires<sup>[*]</sup> that the array's size be multiples of the system's memory page size (<code class="inline terminal">getpagesize()</code> ) so that it lines up with the memory page. Otherwise the contiguous access to the array twice won't work.</p>

            <p>When passing a size to the circular buffer initializer it can be as a suggestion. The actual workable size, aligned to the memory page, can be calculated from the suggestion using the following:</p>

            <div class="code-wrap">
                <code class="clang block">const size_t whole_pages = ( size / getpagesize() ) + ( size % getpagesize() > 0 ? 1 : 0 );
const size_t actual_size = whole_pages * getpagesize();</code>
            </div>

            <p class="footnote"><sup>[*]</sup> <a href="https://www.gnu.org/software/libc/manual/html_node/Memory_002dmapped-I_002fO.html" rel="noreferrer" target="_blank">GNU libC (13.8 Memory-mapped I/O)</a>: <q>...addresses for mapping must be page-aligned, and length values will be rounded up.</q></p>
        </div>

        <h3>Threading</h3>

        <p>A circular buffer is typically used to stream data from a 'producer' thread to a 'consumer' thread so needs have some thread-safety baked in. If the execution of 2 operations overlap, typically fill/drain, there will be a race-condition which can lead to corruption of the buffer and its data.</p>

        <p>There are a couple of things to consider before adding any thread-related operations to the implementation:</p>
        <ul>
            <li>Is the producer or consumer a "passive" participant with an automated loop?</li>
            <li>Is the throughput balanced between the producer and consumer thread?</li>
            <li>Is one thread latency sensitive (i.e. will blocking it be a problem)?</li>
        </ul>

        <p>Depending on the answers, one of several ways of implementing may be chosen. Here are some of these...</p>

        <h4>One mutex to rule them all</h4>

        <figure class="right half-width">
            <a href="figures/thread-single-mutex.svg"><img src="figures/thread-single-mutex.svg" alt="Single-mutex threading" /></a>
            <figcaption>Fig.7 Single mutex threading</figcaption>
        </figure>

        <p>This is the easiest to implement as it just needs 1 mutex. Each operations try to lock it and do their thing and it's first comes, first serve (see fig.7).</p>

        <p>If the mutex is already locked then the operation requesting the lock will wait<sup>[1]</sup> until it's free.</p>

        <p class="footnote"><sup>[1]</sup> <a href="https://linux.die.net/man/3/pthread_mutex_lock" rel="noreferrer" target="_blank"><code class="inline">pthread_mutex_lock</code></a>: <q>...if the mutex is already locked, the calling thread shall block until the mutex becomes available.</q></p>

        <h4>One-sided signalling</h4>

        <figure class="right half-width">
            <a href="figures/thread-single-cond.svg"><img src="figures/thread-single-cond.svg" alt="Single-condition threading" /></a>
            <figcaption>Fig.8 Single condition threading (fill-triggered)</figcaption>
        </figure>

        <p>One sided signalling is useful when the operation receiving the signal is used by a thread running on a dumb loop (i.e. a worker thread just continuously processing data as it receives it). Something to keep in mind is that since the signal receiving operation waits on the signal it <i>blocks</i><sup>[2]</sup> execution and the calling thread by extension.</p>

        <p>The condition can either be setup so that it blocks the producer thread until space is available or the consumer thread until data is available (see fig.8).</p>

        <p>For implementation, a thread condition (<code class="terminal inline">pthread_cond_t</code>) variable is required for signalling. The mutex must also be locked prior to the signal waiting (<code class="terminal inline">pthread_cond_wait</code>)<sup>[2]</sup>. The conditional wait will unlock the mutex while the condition (signal) is not satisfied and then lock it again once satisfied.</p>

        <p class="footnote"><sup>[2]</sup> <a href="https://linux.die.net/man/3/pthread_cond_wait" rel="noreferrer" target="_blank"><code class="inline">pthread_cond_wait</code></a> <q>...shall be called with mutex locked by the calling thread or undefined behavior results. These functions <b>atomically release mutex</b> and cause the calling thread to <b>block</b> on the condition variable...</q></p>

        <h4>Two-sided signalling</h4>

        <figure class="right half-width">
            <a href="figures/thread-double-cond.svg"><img src="figures/thread-double-cond.svg" alt="Double-condition threading" /></a>
            <figcaption>Fig.9 Double condition threading</figcaption>
        </figure>

        <p>Double conditional signalling would only really be useful in the case where both threads are passive workers and sporadic data is passed to the producer like a proxy.</p>

        <p>With this setup both thread's execution is <i>blocked</i> until there are resources available for them to resume their work. The producer thread blocks when there isn't enough space in the buffer for its data to be written. The consumer thread blocks when there is nothing in the buffer. When there isn't enough resources to do what needs to be done CPU cycles are not wasted looping around a while loop since the execution is just blocked (see fig.9).</p>

        <div class="information-box">
            <p>Something to be aware of is that blocking and resuming does have a tiny bit of overhead which will become not so insignificant when compounded in a loop. Whether it is worth it depends entirely on what the circular buffer will be used for.</p>
        </div>

        <h2>Implementation</h2>

        <p>The example implementation uses a producer and consumer thread and has one sided signalling with a try-best drain operation and an all-or-nothing fill operation.</p>

        <p>There's a simple repeatable test based on randomised data that compares the generated source with the target buffer post transfer. The size hint, read/write and source data sizes are all editable via the MACROs at the top of the <code class="inline">main.c</code> file.</p>

        <div class="flex-table">
            <div class="flex-table-row">
                <div class="flex-cell flex-table-heading">Github Repository</div>
                <div class="flex-cell center-align">
                    <a href="https://github.com/An7ar35/circular-buffer" rel="noreferrer" target="_blank">
                        <img class="link-icon" src="../../../img/logos/github-original.svg" alt="Github icon">
                    </a>
                </div>
            </div>
        </div>
    </div>
</article>